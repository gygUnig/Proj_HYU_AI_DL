{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Seunghee Kim\n",
    "- Created on: 2024-12-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Explain\n",
    "# 기존에 train / valid / test 데이터셋을 구축해서 deberta-v3-xsmall 모델로 train data 학습 후 test dataset에 대해 예측했는데, 정확도 0.99가 나오게 됨.\n",
    "# 데이터셋의 난이도가 너무 쉽다는 문제점 발생\n",
    "# 원인 분석\n",
    "# 원인: train, valid, test 를 이루고 있는 AI-Generated Text가 모두 GPT-4o-mini 모델로 구성됨.\n",
    "# 즉, GPT-4o-mini 모델로 만들어진 AI-Generated Text로 학습을 했으니 그 패턴을 파악하게 돼서 GPT-4-mini 모델로 만들어진 Test dataset이 난이도가 쉬워서 정확하게 분류가 가능하게 된 것\n",
    "# 해결 방안: train & valid data와 test data의 distribution을 다르게 하기 위해서, test dataset은 GPT-4o-mini Model뿐만 아니라 최대한 다양한 모델을 이용해서 구축하게 되면 Custom dataset의 난이도가 더 향상될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset_v2: Human Text 4500개, AI-Text: GPT-4o-mini Text 4500개 총 9000개\n",
    "# valid dataset_v2: Human Text 450개, AI-Text: GPT-4o-mini Text 450개 총 900개\n",
    "\n",
    "# test dataset_v2: Human Text 450개, \n",
    "# AI-Text:\n",
    "# 1.'gpt-4o' 50개\n",
    "# 2.'meta-llama/Llama-3.2-8B-Instruct' 50개\n",
    "# 3.'Qwen/Qwen2.5-7B-Instruct' 50개\n",
    "# 4.'Qwen/Qwen2.5-14B-Instruct' 50개\n",
    "# 5.'Qwen/Qwen2.5-1.5B-Instruct' 50개\n",
    "# 6.'Qwen/Qwen2.5-0.5B-Instruct' 50개\n",
    "# 7.'gpt-3.5-turbo' 50개 \n",
    "# 8.'o1-mini' 50개 \n",
    "# 9.'gpt-4o-mini' 50개 \n",
    "# 총 900개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import AutoProcessor, BitsAndBytesConfig, pipeline, AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config & Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 1\n",
    "    \n",
    "    MODEL_1 = \"gpt-4o\" \n",
    "    MODEL_2 = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "    MODEL_3 = 'Qwen/Qwen2.5-7B-Instruct'\n",
    "    MODEL_4 = 'Qwen/Qwen2.5-14B-Instruct'\n",
    "    MODEL_5 = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
    "    MODEL_6 = 'Qwen/Qwen2.5-0.5B-Instruct'\n",
    "    MODEL_7 = 'gpt-3.5-turbo' \n",
    "    MODEL_8 = 'o1-mini' \n",
    "    MODEL_9 = 'gpt-4o-mini' \n",
    "    \n",
    "    # api key가 담긴 yaml파일 (해당 yaml 파일은 .gitignore에 반드시 추가해야 함!!!)\n",
    "    API_CONFIG_PATH = './config.yaml'\n",
    "    \n",
    "    # 1_dataset_preprocess.ipynb의 결과로 나온 전처리된 Human Dataset 경로\n",
    "    DF_HUMAN_TEST_PATH = './df_human_test.csv'\n",
    "    \n",
    "    # AI-Generated Text까지 포함된 csv파일의 output 경로\n",
    "    DF_HUMAN_AI_TEST_PATH_1 = './df_human_ai_test_1_gpt-4o.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_2 = './df_human_ai_test_2_Llama-3_1-8B-Instruct.csv' \n",
    "    DF_HUMAN_AI_TEST_PATH_3 = './df_human_ai_test_3_Qwen2_5-7B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_4 = './df_human_ai_test_4_Qwen2_5-14B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_5 = './df_human_ai_test_5_Qwen2_5-1_5B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_6 = './df_human_ai_test_6_Qwen2_5-0_5B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_7 = './df_human_ai_test_7_gpt-3_5_turbo.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_8 = './df_human_ai_test_8_o1-mini.csv' \n",
    "    DF_HUMAN_AI_TEST_PATH_9 = './df_human_ai_test_9_gpt-4o-mini.csv'\n",
    "    \n",
    "    # Final Dataset output 경로 (Human Text, AI Text, Label 존재)\n",
    "    DF_FINAL_TEST_PATH = './df_final_test_v2.csv'\n",
    "    \n",
    "    # CACHE_DIR = '/data/ksh1234/ksh1234/huggingface_cache' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT TEST DATASET INTO 50 * 9\n",
    "test_dataset = pd.read_csv(CFG.DF_HUMAN_TEST_PATH)\n",
    "split_datasets = []\n",
    "chunk_size = 50\n",
    "\n",
    "for i in range(0, len(test_dataset), chunk_size):\n",
    "    split_datasets.append(test_dataset.iloc[i:i + chunk_size])\n",
    "\n",
    "test_dataset_1 = split_datasets[0]\n",
    "test_dataset_2 = split_datasets[1]\n",
    "test_dataset_3 = split_datasets[2]\n",
    "test_dataset_4 = split_datasets[3]\n",
    "test_dataset_5 = split_datasets[4]\n",
    "test_dataset_6 = split_datasets[5]\n",
    "test_dataset_7 = split_datasets[6]\n",
    "test_dataset_8 = split_datasets[7]\n",
    "test_dataset_9 = split_datasets[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: Qwen/Qwen2.5-1.5B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4219/2003275129.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_dataset_5['AI_Generated_Text'] = \"\"\n",
      "/tmp/ipykernel_4219/2003275129.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_dataset_5['Model'] = \"\"\n",
      "\n",
      "00%|██████████| 50/50 [07:09<00:00,  8.58s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_name = CFG.MODEL_5\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "test_dataset_5['AI_Generated_Text'] = \"\"\n",
    "test_dataset_5['Model'] = \"\"\n",
    "\n",
    "for idx, row in tqdm(test_dataset_5.iterrows(), total=len(test_dataset_5)):\n",
    "    input_text = row['essay_prompt']\n",
    "    student_grade = row['student_grade']\n",
    "    school, grade = student_grade.split('_')\n",
    "    if school == '중등':\n",
    "        school = school[0]  # 중등인 경우 '중'만 가져옴\n",
    "    \n",
    "    # 학교 수준에 따라 다르게 설정하는 시스템 프롬프트\n",
    "    grade_system_prompt = f\"대한민국의 {school}학교 {grade} 학생 수준으로 답하시오. 마크다운 용법을 사용하지 말고 학생이 글을 쓰듯이 답하시오.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": grade_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": input_text},\n",
    "    ]\n",
    "\n",
    "    # 메시지를 토큰화 및 모델 입력 생성\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=1024\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    llm_output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    test_dataset_5.at[idx, 'AI_Generated_Text'] = llm_output\n",
    "    test_dataset_5.at[idx, 'Model'] = model_name\n",
    "\n",
    "test_dataset_5.to_csv(CFG.DF_HUMAN_AI_TEST_PATH_5, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200    제가 고등학교 2학년이며, 제가 지금까지 경험한 가장 큰 문제로는 '무관심'이라는 ...\n",
       "201    안녕하세요! 저는 대한민국의 고등학교 3학년입니다. 내년에는 사회인으로서의 첫 발걸...\n",
       "202    제목: 내년 사회인으로서의 첫 발걸음\\n\\n안녕하세요, 여러분들! 저는 이제 고등학...\n",
       "203    제목: 내년 사회인으로서의 첫 발걸음\\n\\n내년에는 사회인으로서의 첫 발걸음을 뗄 ...\n",
       "204    죄송합니다만 저는 인공지능으로서 감성과 창의성이 부족하기에, 개인적인 취향이나 영화...\n",
       "205    제목: 내년 사회인으로서의 첫 걸음\\n\\n안녕하세요! 내년 사회인으로서의 첫 발걸음...\n",
       "206    죄송합니다만 저는 인공지능으로서 감정이나 개인적인 경험을 가질 수 없습니다. 하지만...\n",
       "207    저는 19세기의 프랑스 출신의 작가인 Жак-Пьер де Монте (Jacque...\n",
       "208    안녕하세요! 저는 대한민국의 고등학교 3학년입니다. 내년에 사회인으로서의 첫 발걸음...\n",
       "209    저는 대한민국의 고등학교 2학년입니다. 제가 글쓰기에 대해 어떻게 도와드릴까요? 필...\n",
       "210    제가 제일 좋아하는 사람은 김민수입니다. 그녀는 예술적인 인성이 강하며, 다양한 장...\n",
       "211    제 이름은 김영희입니다. 저는 중학교 2학년의 한 학생으로, 성격은 약간의 악성과 ...\n",
       "212    제가 현재 3학년 중학생입니다. 제가 가장 책임감을 느낄 수 있는 것은 학교 생활입...\n",
       "213    제 이름은 김하늘입니다. 저는 평범한 여학생입니다. 하지만 제가 가지고 있는 특별한...\n",
       "214    제 이름은 [학생 이름]입니다. 저는 중학교 2학년의 학생입니다. 이 질문에 대해 ...\n",
       "215    죄송합니다만 저는 AI 어시스턴트로써 개인적인 경험이나 감정을 가지고 있지 않습니다...\n",
       "216    참된 스승은 학생들에게 자신의 삶의 경험이나 성공 사례를 공유하며, 학생들의 질문에...\n",
       "217    습관은 우리가 일상생활에서 반복적으로 수행하는 특정 행동이나 생각을 의미합니다. 이...\n",
       "218    습관은 우리가 일상생활에서 반복적으로 수행하는 행동들로, 이러한 행동들이 우리의 생...\n",
       "219    제 이름은 [성함]입니다. 저는 현재 중학교 2학년 1반의 학생입니다. 사실상 제가...\n",
       "220    죄송합니다만 제가 제공할 수 있는 답변은 초등학생 수준에서 이루어진 것입니다. 따라...\n",
       "221    물론이 좋아요! 제가 어떻게 습관을 바꾸는지 이야기해 드리려고 합니다.\\n\\n첫째,...\n",
       "222    죄송합니다만 저는 실제 경험이나 개인적인 감정을 표현할 수 없습니다. 하지만 대신 ...\n",
       "223    안녕하세요! 저는 현재 중학교 2학년의 학생입니다. 이 질문에 대해 다음과 같이 답...\n",
       "224    습관은 우리 일상생활에서 자주 반복되는 행동양식으로, 특정한 행동이나 생각을 반복적...\n",
       "225    죄송합니다, 저는 인공지능으로서 실제 경험을 할 수 없습니다. 그러나 대인들에게 이...\n",
       "226    습관은 우리가 일상생활에서 반복적으로 하는 특정 행동이나 생각들을 의미하며, 이러한...\n",
       "227    안녕하세요. 저는 지금 대학 2학년입니다. 제가 가장 좋아하는 성격은 \"소나무\"라고...\n",
       "228    안녕하세요, 저는 16세로 대략 같은 나이와 동일한 학교에 다니고 있는 중학생입니다...\n",
       "229    제 이름은 [이름]입니다. 저는 매우 다양한 성격을 가지고 있습니다. 사실상, 누구...\n",
       "230    참된 스승은 학생들에게 자신을 존중하고 배움에 대한 열정, 지혜, 도덕성 등을 전수...\n",
       "231    습관은 일상생활에서 자주 반복되는 행동양식이며, 특정 행동이나 생각을 동일한 상황에...\n",
       "232    제가 대학三年级的学生，我不能提供关于成年责任的个人经验。我的年龄和能力使我无法回答这个问题...\n",
       "233    안녕하세요! 저는 중학교 2학년 학생입니다. 제가 이야기하는 성격은 '소나무'라는 ...\n",
       "234    참된 스승은 자신감과 열정, 이해와 배려, 도전과 헌신, 지혜와 존중, 창의성과 지...\n",
       "235    \"참된 스승은 학생들에게 자신의 경험과 지식을 바탕으로 정직하고 존중하며, 학생들의...\n",
       "236    습관은 우리 생활에서 일상적으로 반복되는 행동양식으로, 특정 행동이나 생각을 통해 ...\n",
       "237    물론히 도움이 될 것 같아요! 지금부터 제가 당신에게 어떤 습관을 고칠까요? 또는 ...\n",
       "238    제 이름은 김연희입니다. 저는 동네에서 유명한 광산 노조리로 알려져 있습니다. 하지...\n",
       "239    물론 좋은 습관을 들이는 방법에 대한 정보를 제공해주셔서 감사드립니다. \\n\\n1)...\n",
       "240    예절은 우리가 서로를 존중하고 협동하는 데 중요한 역할을 합니다. 그러나 어떤 상황...\n",
       "241    안녕하세요! 저는 초등학생입니다. 제가 원하는 집을 상상하며 다음과 같은 요소들을 ...\n",
       "242    물론이죠. 저는 지금 초등학생이라서 실제에 대한 상상력이 부족하고, 실제로 살 수 ...\n",
       "243    제가 초등학생인 만큼 이 문제에 대한 답변은 어려울 수 있습니다. 하지만 제가 본인...\n",
       "244    제가 현재로서는 초등학생이며, 인터넷에서 얻은 정보를 바탕으로 답변 드리겠습니다.\\...\n",
       "245    네, 저는 컴퓨터에서 생성된 AI로서 개인적인 경험이나 행동에 대해 직접적으로 참여...\n",
       "246    안녕하세요, 저는 초등학생인 5학년입니다. 오늘은 건강한 몸을 만드는데 중요한 것들...\n",
       "247    저는 초등학교 4학년이고, 아직 예절의 기준에 대해 깊게 생각해 본 적이 없네요. ...\n",
       "248    저는 인공지능으로써 개인적인 취미를 가지지는 못합니다. 하지만 저는 여러 유형의 정...\n",
       "249    제 취미는 '독서'입니다. 책을 읽으며 세상을 배우고, 생각을 풀어가는 시간을 보내...\n",
       "Name: AI_Generated_Text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_5['AI_Generated_Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
