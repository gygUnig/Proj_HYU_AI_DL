{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Seunghee Kim\n",
    "- Created on: 2024-12-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Explain\n",
    "# 기존에 train / valid / test 데이터셋을 구축해서 deberta-v3-xsmall 모델로 train data 학습 후 test dataset에 대해 예측했는데, 정확도 0.99가 나오게 됨.\n",
    "# 데이터셋의 난이도가 너무 쉽다는 문제점 발생\n",
    "# 원인 분석\n",
    "# 원인: train, valid, test 를 이루고 있는 AI-Generated Text가 모두 GPT-4o-mini 모델로 구성됨.\n",
    "# 즉, GPT-4o-mini 모델로 만들어진 AI-Generated Text로 학습을 했으니 그 패턴을 파악하게 돼서 GPT-4-mini 모델로 만들어진 Test dataset이 난이도가 쉬워서 정확하게 분류가 가능하게 된 것\n",
    "# 해결 방안: train & valid data와 test data의 distribution을 다르게 하기 위해서, test dataset은 GPT-4o-mini Model뿐만 아니라 최대한 다양한 모델을 이용해서 구축하게 되면 Custom dataset의 난이도가 더 향상될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset_v2: Human Text 4500개, AI-Text: GPT-4o-mini Text 4500개 총 9000개\n",
    "# valid dataset_v2: Human Text 450개, AI-Text: GPT-4o-mini Text 450개 총 900개\n",
    "\n",
    "# test dataset_v2: Human Text 450개, \n",
    "# AI-Text:\n",
    "# 1.'gpt-4o' 50개\n",
    "# 2.'meta-llama/Llama-3.2-8B-Instruct' 50개\n",
    "# 3.'Qwen/Qwen2.5-7B-Instruct' 50개\n",
    "# 4.'Qwen/Qwen2.5-14B-Instruct' 50개\n",
    "# 5.'Qwen/Qwen2.5-1.5B-Instruct' 50개\n",
    "# 6.'Qwen/Qwen2.5-0.5B-Instruct' 50개\n",
    "# 7.'gpt-3.5-turbo' 50개 \n",
    "# 8.'o1-mini' 50개 \n",
    "# 9.'gpt-4o-mini' 50개 \n",
    "# 총 900개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config & Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 1\n",
    "    \n",
    "    MODEL_1 = \"gpt-4o\" \n",
    "    MODEL_2 = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "    MODEL_3 = 'Qwen/Qwen2.5-7B-Instruct'\n",
    "    MODEL_4 = 'Qwen/Qwen2.5-14B-Instruct'\n",
    "    MODEL_5 = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
    "    MODEL_6 = 'Qwen/Qwen2.5-0.5B-Instruct'\n",
    "    MODEL_7 = 'gpt-3.5-turbo' \n",
    "    MODEL_8 = 'o1-mini' \n",
    "    MODEL_9 = 'gpt-4o-mini' \n",
    "    \n",
    "    # api key가 담긴 yaml파일 (해당 yaml 파일은 .gitignore에 반드시 추가해야 함!!!)\n",
    "    API_CONFIG_PATH = './config.yaml'\n",
    "    \n",
    "    # 1_dataset_preprocess.ipynb의 결과로 나온 전처리된 Human Dataset 경로\n",
    "    DF_HUMAN_TEST_PATH = './df_human_test.csv'\n",
    "    \n",
    "    # AI-Generated Text까지 포함된 csv파일의 output 경로\n",
    "    DF_HUMAN_AI_TEST_PATH_1 = './df_human_ai_test_1_gpt-4o.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_2 = './df_human_ai_test_2_Llama-3_1-8B-Instruct.csv' \n",
    "    DF_HUMAN_AI_TEST_PATH_3 = './df_human_ai_test_3_Qwen2_5-7B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_4 = './df_human_ai_test_4_Qwen2_5-14B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_5 = './df_human_ai_test_5_Qwen2_5-1_5B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_6 = './df_human_ai_test_6_Qwen2_5-0_5B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_7 = './df_human_ai_test_7_gpt-3_5_turbo.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_8 = './df_human_ai_test_8_o1-mini.csv' \n",
    "    DF_HUMAN_AI_TEST_PATH_9 = './df_human_ai_test_9_gpt-4o-mini.csv'\n",
    "    \n",
    "    # Final Dataset output 경로 (Human Text, AI Text, Label 존재)\n",
    "    DF_FINAL_TEST_PATH = './df_final_test_v2.csv'\n",
    "    \n",
    "    # CACHE_DIR = '/data/ksh1234/ksh1234/huggingface_cache' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT TEST DATASET INTO 50 * 9\n",
    "test_dataset = pd.read_csv(CFG.DF_HUMAN_TEST_PATH)\n",
    "split_datasets = []\n",
    "chunk_size = 50\n",
    "\n",
    "for i in range(0, len(test_dataset), chunk_size):\n",
    "    split_datasets.append(test_dataset.iloc[i:i + chunk_size])\n",
    "\n",
    "test_dataset_1 = split_datasets[0]\n",
    "test_dataset_2 = split_datasets[1]\n",
    "test_dataset_3 = split_datasets[2]\n",
    "test_dataset_4 = split_datasets[3]\n",
    "test_dataset_5 = split_datasets[4]\n",
    "test_dataset_6 = split_datasets[5]\n",
    "test_dataset_7 = split_datasets[6]\n",
    "test_dataset_8 = split_datasets[7]\n",
    "test_dataset_9 = split_datasets[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Qwen/Qwen2.5-7B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bb6581401a4d859a671e8c64590f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19dbfe4522334a55a7d97dbf68871fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd697a6342742d3bf770507c96a579d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd0cd8aecd245cea02bc00de18bd520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1678f6d28d8144b3b54e313cdae52cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a836f6f2bd4dc9829d9e4b2f7abb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b41596741d4b4e997a8ee4eaf849d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d453607bca4e44fd9f1c66bb3ce245e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d755029df4c40bc922e8870a09dfe94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a08321673244af80a1a852fd88e7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ba93bcd061409f8b14058e3d8123b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360fe6e5039c457c942d0fb36d2bc9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c83299df2f74b5baf6c8be1f97755cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2133/2969499011.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_dataset_3['AI_Generated_Text'] = \"\"\n",
      "/tmp/ipykernel_2133/2969499011.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_dataset_3['Model'] = \"\"\n",
      "\n",
      "00%|██████████| 50/50 [09:50<00:00, 11.82s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_name = CFG.MODEL_3\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "test_dataset_3['AI_Generated_Text'] = \"\"\n",
    "test_dataset_3['Model'] = \"\"\n",
    "\n",
    "for idx, row in tqdm(test_dataset_3.iterrows(), total=len(test_dataset_3)):\n",
    "    input_text = row['essay_prompt']\n",
    "    student_grade = row['student_grade']\n",
    "    school, grade = student_grade.split('_')\n",
    "    if school == '중등':\n",
    "        school = school[0]  # 중등인 경우 '중'만 가져옴\n",
    "    \n",
    "    # 학교 수준에 따라 다르게 설정하는 시스템 프롬프트\n",
    "    grade_system_prompt = f\"대한민국의 {school}학교 {grade} 학생 수준으로 답하시오. 마크다운 용법을 사용하지 말고 학생이 글을 쓰듯이 답하시오.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": grade_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": input_text},\n",
    "    ]\n",
    "\n",
    "    # 메시지를 토큰화 및 모델 입력 생성\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=1024\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    llm_output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    test_dataset_3.at[idx, 'AI_Generated_Text'] = llm_output\n",
    "    test_dataset_3.at[idx, 'Model'] = model_name\n",
    "\n",
    "test_dataset_3.to_csv(CFG.DF_HUMAN_AI_TEST_PATH_3, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    우리 주변에도 양성평등 문제가 있다는 생각이 들어요. 특히, 여성들이 직장에서 겪는...\n",
       "101    우리 주변에서 발견할 수 있는 양성평등 문제 중 하나는 회사에서 여성 직원들이 주로...\n",
       "102    우리 주변에도 아직 양성평등 문제가 있어요. 예를 들어 회사에서 여성 직원들이 남성...\n",
       "103    우리 주변에서 양성평등 문제가 많이 발생하는데요. 특히 회사에서 여성 직원들이 주는...\n",
       "104    우리 주변에 있는 양성평등 문제 중 하나는 여학생들이 남학생들보다 과학과 기술 분야...\n",
       "105    우리 주변에는 아직 양성평등 문제가 많이 남아있습니다. 특히 회사에서 여성들이 주도...\n",
       "106    우리 주변에는 여전히 양성평등 문제들이 있어요. 예를 들어, 회사에서 여성 직원들이...\n",
       "107    협소 시설 건설에 대해 생각해보면 여러 의견들이 있을 수 있어요. 하지만 저는 협소...\n",
       "108    혼란스게도 혐오 시설 문제는 많은 이슈들이 얽혀 있어서 쉽지 않은 결정이 필요합니다...\n",
       "109    우리 주변에도 양성평등 문제가 존재합니다. 예를 들어, 회사에서 여성 직원들이 남성...\n",
       "110    우리 주변에도 양성평등 문제가 아직 존재합니다. 예를 들어, 회사에서는 여성이 남성...\n",
       "111    우리 주변에도 양성평등 문제들이 많이 있습니다. 특히 직장에서 여성들이 겪는 문제들...\n",
       "112    우리 주변에서도 여전히 양성평등 문제가 존재합니다. 예를 들어, 회사에서는 여성이 ...\n",
       "113    우리 주변에서 쉽게 볼 수 있는 양성평등 문제 중 하나는 회사에서의 여성 경력 단절...\n",
       "114    우리 주변에도 양성평등 문제가 많이 있습니다. 예를 들어 회사에서는 여성 직원들이 ...\n",
       "115    혼란스게 느껴지는 문제 같네요. 혐오 시설은 우리 생활에 필요한 것들이라서 건설이 ...\n",
       "116    우리 주변에도 여전히 양성평등 문제들이 있다는 생각이 들어요. 특히 회사에서 이런 ...\n",
       "117    우리 주변에는 여전히 양성평등 문제들이 많이 있습니다. 특히, 직장에서의 성차별 문...\n",
       "118    우리 주변에서 양성평등 문제 중 하나는 여성들이 회사에서 더 많이 하게 되는 비효율...\n",
       "119    우리 주변에서 양성평등 문제 중 하나는 여성이 직장에서 남성보다 평균적으로 월급이 ...\n",
       "120    한류가 이렇게 세계적으로 사랑받게 된 것은 한국 문화의 독특함과 재미 덕분입니다. ...\n",
       "121    학교 폭력의 근본적인 이유는 여러 가지가 있을 거라고 생각해요. 먼저, 부모님이나 ...\n",
       "122    학교 폭력의 근본적인 이유는 여러 가지가 있을 것 같아요. 제 생각에는 다음과 같은...\n",
       "123    표절 검사를 하게 된다면, 저는 주로 논문과 책을 대상으로 검사하도록 하겠습니다. ...\n",
       "124    이 문제에 대해서는 정말 걱정이네요. 중국이 우리 한류를 자기 것으로 주장하려고 하...\n",
       "125    표절 검사를 위한 기준을 만들 때는 창조성과 원작자의 권리를 균형있게 고려해야 합니...\n",
       "126    한류 열풍은 정말 좋은 현상이죠. 한국의 문화가 세계적으로 사랑받는 것은 한국 사람...\n",
       "127    표절 검사를 하게 된다면 여러 분야에서 적용할 수 있는 기준을 세우는 것이 중요할 ...\n",
       "128    학교 폭력의 근본적인 이유는 여러 가지가 있지만, 저는 개인적으로 학생들의 정서적 ...\n",
       "129    한류 열풍이 이렇게 큰데 중국이 그렇게 억지 주장하면 안되겠죠. 우리는 이렇게 대처...\n",
       "130    표절 검사는 창작물을 보호하면서도 자유롭게 창조할 수 있는 환경을 만드는데 중요해요...\n",
       "131    학교 폭력의 근본적인 이유는 여러 가지가 있지만, 가장 큰 이유는 아마도 '친구관계...\n",
       "132    한류 열풍은 한국 문화가 세계적으로 인정받게 해주어서 정말 좋습니다. 그런데 중국이...\n",
       "133    중국이 한국 문화를 자신의 것으로 착각하고 있어요. 이건 잘못된 거예요. 한국 문화...\n",
       "134    표절 검사를 위한 기준을 만드는 것은 매우 중요한 일이에요. 그래서 저는 여러 분야...\n",
       "135    표절 검사는 창작물을 보호하면서도 창조성을 견인하기 위한 중요한 일입니다. 저는 각...\n",
       "136    표절 검사는 창작물을 보호하면서도 창조성과 자유를 존중하기 위해 중요합니다. 저는 ...\n",
       "137    학교 폭력의 근본적인 이유로는 여러 가지가 있을 거 같아요. 먼저, 많은 친구들이 ...\n",
       "138    한류 열풍이 이런 식으로 억지 주장으로 변질된다니 정말 안타깝습니다. 우리가 가만히...\n",
       "139    표절 검사는 창작물의 독창성을 보호하면서 동시에 창조적인 자유를 유지하기 위해 중요...\n",
       "140    학교 폭력의 근본적인 이유는 여러 가지가 있지만, 저는 다음과 같은 이유들을 중요하...\n",
       "141    표절 검사는 창작물을 보호하면서도 자유로운 표현을 지키기 위한 중요한 일입니다. 저...\n",
       "142    학교 폭력의 근본적인 이유는 여러 가지가 있을 것 같아요. 우선, 가정에서 부모님이...\n",
       "143    한류 열풍이 이렇게 큰 규모로 확장되면서, 한국의 문화가 해외에서 인기가 높아지는 ...\n",
       "144    학교 폭력의 근본적인 이유는 여러 가지가 있을 수 있지만, 저는 크게 두 가지로 보...\n",
       "145    학교 폭력의 근본적인 이유는 여러 가지가 있을 수 있지만, 제 생각에는 다음과 같은...\n",
       "146    표절 검사를 할 분야로는 '게임'을 선택하겠습니다. 게임은 요즘 많이 발전하고 있어...\n",
       "147    표절 검사를 할 때 중요한 것은 창작자의 독창성을 보호하면서도 자유로운 창조를 격려...\n",
       "148    중국이 이렇게 한국 문화를 자신의 것으로 치부하려는 행동은 참 안 좋은 것 같아요....\n",
       "149    한류 열풍이 이렇게 큰 규모로 확장되다니 정말 놀랍습니다. 하지만 중국이 이런 행동...\n",
       "Name: AI_Generated_Text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_3['AI_Generated_Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
