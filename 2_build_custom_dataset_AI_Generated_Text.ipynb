{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Seunghee Kim\n",
    "- Created on: 2024-11-20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Explain  \n",
    "1_dataset_preprocess.ipynb의 결과로 나오게 된 df_human_train.csv, df_human_valid.csv, df_human_test.csv 데이터셋에 대해서, 동일한 'essay_prompt'를 OpenAI의 GPT-4o-mini 모델에게 제공해서 AI-Generated Text를 얻는 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config & Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 1\n",
    "    MODEL = \"gpt-4o-mini\"\n",
    "    \n",
    "    # api key가 담긴 yaml파일 (해당 yaml 파일은 .gitignore에 반드시 추가해야 함!!!)\n",
    "    API_CONFIG_PATH = './config.yaml'\n",
    "    \n",
    "    # 1_dataset_preprocess.ipynb의 결과로 나온 전처리된 Human Dataset 경로\n",
    "    DF_HUMAN_TRAIN_PATH = './df_human_train.csv'\n",
    "    DF_HUMAN_VALID_PATH = './df_human_valid.csv'\n",
    "    DF_HUMAN_TEST_PATH = './df_human_test.csv'\n",
    "    \n",
    "    # AI-Generated Text까지 포함된 csv파일의 output 경로\n",
    "    DF_HUMAN_AI_TRAIN_PATH = './df_human_ai_train.csv'\n",
    "    DF_HUMAN_AI_VALID_PATH = './df_human_ai_valid.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH = './df_human_ai_test.csv'\n",
    "    \n",
    "    # Final Dataset output 경로 (Human Text, AI Text, Label 존재)\n",
    "    DF_FINAL_TRAIN_PATH = './df_final_train.csv'\n",
    "    DF_FINAL_VALID_PATH = './df_final_valid.csv'\n",
    "    DF_FINAL_TEST_PATH = './df_final_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml파일에 존재하는 api key를 load 하는 함수\n",
    "def load_api_key(yaml_file):\n",
    "    with open(yaml_file, 'r', encoding='utf-8') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config['openai']['api_key_ksh']\n",
    "\n",
    "api_key = load_api_key(CFG.API_CONFIG_PATH)\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make AI-Generated Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(CFG.DF_HUMAN_TRAIN_PATH)\n",
    "\n",
    "# test\n",
    "train_dataset = train_dataset.head(3)\n",
    "\n",
    "train_dataset['AI_Generated_Text'] = \"\"\n",
    "\n",
    "for idx, row in tqdm(train_dataset.iterrows(), total=len(train_dataset)):\n",
    "    input_text = row['essay_prompt']\n",
    "    student_grade = row['student_grade']\n",
    "    school, grade = student_grade.split('_')\n",
    "    if school == '중등':\n",
    "        school = school[0] # 중등인 경우 '중'만 가져옴\n",
    "    \n",
    "    # 학교 수준에 따라 다르게 설정하는 시스템 프롬프트\n",
    "    # ex) \"너는 대한민국의 고등학교 2학년 학생이다.\"\n",
    "    grade_system_prompt = f\"너는 대한민국의 {school}학교 {grade} 학생이다.\"\n",
    "    # print(grade_system_prompt)\n",
    "    # print('=================')\n",
    "    # print(input_text)\n",
    "    # print('=================')\n",
    "    response = client.chat.completions.create(\n",
    "        model=CFG.MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": grade_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": input_text}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    llm_output = response.choices[0].message.content\n",
    "    # print(llm_output)\n",
    "    # print('=================')\n",
    "    # LLM이 생성한 Text를 'AI_Generated_Text' 열에 추가\n",
    "    train_dataset.at[idx, 'AI_Generated_Text'] = llm_output\n",
    "\n",
    "train_dataset.to_csv(CFG.DF_HUMAN_AI_TRAIN_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = pd.read_csv(CFG.DF_HUMAN_VALID_PATH)\n",
    "valid_dataset['AI_Generated_Text'] = \"\"\n",
    "\n",
    "\n",
    "for idx, row in tqdm(valid_dataset.iterrows(), total=len(valid_dataset)):\n",
    "    input_text = row['essay_prompt']\n",
    "    student_grade = row['student_grade']\n",
    "    school, grade = student_grade.split('_')\n",
    "    if school == '중등':\n",
    "        school = school[0] # 중등인 경우 '중'만 가져옴\n",
    "    \n",
    "    # 학교 수준에 따라 다르게 설정하는 시스템 프롬프트\n",
    "    # ex) \"너는 대한민국의 고등학교 2학년 학생이다.\"\n",
    "    grade_system_prompt = f\"너는 대한민국의 {school}학교 {grade} 학생이다.\"\n",
    "    # print(grade_system_prompt)\n",
    "    # print('=================')\n",
    "    # print(input_text)\n",
    "    # print('=================')\n",
    "    response = client.chat.completions.create(\n",
    "        model=CFG.MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": grade_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": input_text}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    llm_output = response.choices[0].message.content\n",
    "    # print(llm_output)\n",
    "    # print('=================')\n",
    "    # LLM이 생성한 Text를 'AI_Generated_Text' 열에 추가\n",
    "    valid_dataset.at[idx, 'AI_Generated_Text'] = llm_output\n",
    "\n",
    "\n",
    "valid_dataset.to_csv(CFG.DF_HUMAN_AI_VALID_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(CFG.DF_HUMAN_TEST_PATH)\n",
    "test_dataset['AI_Generated_Text'] = \"\"\n",
    "\n",
    "\n",
    "for idx, row in tqdm(test_dataset.iterrows(), total=len(test_dataset)):\n",
    "    input_text = row['essay_prompt']\n",
    "    student_grade = row['student_grade']\n",
    "    school, grade = student_grade.split('_')\n",
    "    if school == '중등':\n",
    "        school = school[0] # 중등인 경우 '중'만 가져옴\n",
    "    \n",
    "    # 학교 수준에 따라 다르게 설정하는 시스템 프롬프트\n",
    "    # ex) \"너는 대한민국의 고등학교 2학년 학생이다.\"\n",
    "    grade_system_prompt = f\"너는 대한민국의 {school}학교 {grade} 학생이다.\"\n",
    "    # print(grade_system_prompt)\n",
    "    # print('=================')\n",
    "    # print(input_text)\n",
    "    # print('=================')\n",
    "    response = client.chat.completions.create(\n",
    "        model=CFG.MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": grade_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": input_text}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    llm_output = response.choices[0].message.content\n",
    "    # print(llm_output)\n",
    "    # print('=================')\n",
    "    # LLM이 생성한 Text를 'AI_Generated_Text' 열에 추가\n",
    "    test_dataset.at[idx, 'AI_Generated_Text'] = llm_output\n",
    "\n",
    "\n",
    "test_dataset.to_csv(CFG.DF_HUMAN_AI_TEST_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Final Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
