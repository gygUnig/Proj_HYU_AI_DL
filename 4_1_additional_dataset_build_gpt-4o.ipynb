{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Seunghee Kim\n",
    "- Created on: 2024-12-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Explain\n",
    "# 기존에 train / valid / test 데이터셋을 구축해서 deberta-v3-xsmall 모델로 train data 학습 후 test dataset에 대해 예측했는데, 정확도 0.99가 나오게 됨.\n",
    "# 데이터셋의 난이도가 너무 쉽다는 문제점 발생\n",
    "# 원인 분석\n",
    "# 원인: train, valid, test 를 이루고 있는 AI-Generated Text가 모두 GPT-4o-mini 모델로 구성됨.\n",
    "# 즉, GPT-4o-mini 모델로 만들어진 AI-Generated Text로 학습을 했으니 그 패턴을 파악하게 돼서 GPT-4-mini 모델로 만들어진 Test dataset이 난이도가 쉬워서 정확하게 분류가 가능하게 된 것\n",
    "# 해결 방안: train & valid data와 test data의 distribution을 다르게 하기 위해서, test dataset은 GPT-4o-mini Model뿐만 아니라 최대한 다양한 모델을 이용해서 구축하게 되면 Custom dataset의 난이도가 더 향상될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset_v2: Human Text 4500개, AI-Text: GPT-4o-mini Text 4500개 총 9000개\n",
    "# valid dataset_v2: Human Text 450개, AI-Text: GPT-4o-mini Text 450개 총 900개\n",
    "\n",
    "# test dataset_v2: Human Text 450개, \n",
    "# AI-Text:\n",
    "# 1.'gpt-4o' 50개\n",
    "# 2.'meta-llama/Llama-3.2-8B-Instruct' 50개\n",
    "# 3.'Qwen/Qwen2.5-7B-Instruct' 50개\n",
    "# 4.'Qwen/Qwen2.5-14B-Instruct' 50개\n",
    "# 5.'Qwen/Qwen2.5-1.5B-Instruct' 50개\n",
    "# 6.'Qwen/Qwen2.5-0.5B-Instruct' 50개\n",
    "# 7.'gpt-3.5-turbo' 50개 \n",
    "# 8.'o1-mini' 50개 \n",
    "# 9.'gpt-4o-mini' 50개 \n",
    "# 총 900개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config & Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 1\n",
    "    \n",
    "    MODEL_1 = \"gpt-4o\" \n",
    "    MODEL_2 = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "    MODEL_3 = 'Qwen/Qwen2.5-7B-Instruct'\n",
    "    MODEL_4 = 'Qwen/Qwen2.5-14B-Instruct'\n",
    "    MODEL_5 = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
    "    MODEL_6 = 'Qwen/Qwen2.5-0.5B-Instruct'\n",
    "    MODEL_7 = 'gpt-3.5-turbo' \n",
    "    MODEL_8 = 'o1-mini' \n",
    "    MODEL_9 = 'gpt-4o-mini' \n",
    "    \n",
    "    # api key가 담긴 yaml파일 (해당 yaml 파일은 .gitignore에 반드시 추가해야 함!!!)\n",
    "    API_CONFIG_PATH = './config.yaml'\n",
    "    \n",
    "    # 1_dataset_preprocess.ipynb의 결과로 나온 전처리된 Human Dataset 경로\n",
    "    DF_HUMAN_TEST_PATH = './df_human_test.csv'\n",
    "    \n",
    "    # AI-Generated Text까지 포함된 csv파일의 output 경로\n",
    "    DF_HUMAN_AI_TEST_PATH_1 = './df_human_ai_test_1_gpt-4o.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_2 = './df_human_ai_test_2_Llama-3_1-8B-Instruct.csv' \n",
    "    DF_HUMAN_AI_TEST_PATH_3 = './df_human_ai_test_3_Qwen2_5-7B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_4 = './df_human_ai_test_4_Qwen2_5-14B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_5 = './df_human_ai_test_5_Qwen2_5-1_5B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_6 = './df_human_ai_test_6_Qwen2_5-0_5B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_7 = './df_human_ai_test_7_gpt-3_5_turbo.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_8 = './df_human_ai_test_8_o1-mini.csv' \n",
    "    DF_HUMAN_AI_TEST_PATH_9 = './df_human_ai_test_9_gpt-4o-mini.csv'\n",
    "    \n",
    "    # Final Dataset output 경로 (Human Text, AI Text, Label 존재)\n",
    "    DF_FINAL_TEST_PATH = './df_final_test_v2.csv'\n",
    "    \n",
    "    # CACHE_DIR = '/data/ksh1234/ksh1234/huggingface_cache' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml파일에 존재하는 openai api key를 load 하는 함수\n",
    "def load_api_key(yaml_file):\n",
    "    with open(yaml_file, 'r', encoding='utf-8') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config['openai']['api_key_ksh']\n",
    "\n",
    "api_key = load_api_key(CFG.API_CONFIG_PATH)\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT TEST DATASET INTO 50 * 9\n",
    "test_dataset = pd.read_csv(CFG.DF_HUMAN_TEST_PATH)\n",
    "split_datasets = []\n",
    "chunk_size = 50\n",
    "\n",
    "for i in range(0, len(test_dataset), chunk_size):\n",
    "    split_datasets.append(test_dataset.iloc[i:i + chunk_size])\n",
    "\n",
    "test_dataset_1 = split_datasets[0]\n",
    "test_dataset_2 = split_datasets[1]\n",
    "test_dataset_3 = split_datasets[2]\n",
    "test_dataset_4 = split_datasets[3]\n",
    "test_dataset_5 = split_datasets[4]\n",
    "test_dataset_6 = split_datasets[5]\n",
    "test_dataset_7 = split_datasets[6]\n",
    "test_dataset_8 = split_datasets[7]\n",
    "test_dataset_9 = split_datasets[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1. gpt-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_1['AI_Generated_Text'] = \"\"\n",
    "test_dataset_1['Model'] = \"\"\n",
    "\n",
    "for idx, row in tqdm(test_dataset_1.iterrows(), total=len(test_dataset_1)):\n",
    "    input_text = row['essay_prompt']\n",
    "    student_grade = row['student_grade']\n",
    "    school, grade = student_grade.split('_')\n",
    "    if school == '중등':\n",
    "        school = school[0] # 중등인 경우 '중'만 가져옴\n",
    "    \n",
    "    # 학교 수준에 따라 다르게 설정하는 시스템 프롬프트\n",
    "    grade_system_prompt = f\"대한민국의 {school}학교 {grade} 학생 수준으로 답하시오. 마크다운 용법을 사용하지 말고 학생이 글을 쓰듯이 답하시오.\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=CFG.MODEL_1,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": grade_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": input_text}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    llm_output = response.choices[0].message.content\n",
    "    # LLM이 생성한 Text를 'AI_Generated_Text' 열에 추가\n",
    "    test_dataset_1.at[idx, 'AI_Generated_Text'] = llm_output\n",
    "    test_dataset_1.at[idx, 'Model'] = CFG.MODEL_1\n",
    "\n",
    "test_dataset_1.to_csv(CFG.DF_HUMAN_AI_TEST_PATH_1, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
