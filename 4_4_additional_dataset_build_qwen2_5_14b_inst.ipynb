{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Seunghee Kim\n",
    "- Created on: 2024-12-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Explain\n",
    "# 기존에 train / valid / test 데이터셋을 구축해서 deberta-v3-xsmall 모델로 train data 학습 후 test dataset에 대해 예측했는데, 정확도 0.99가 나오게 됨.\n",
    "# 데이터셋의 난이도가 너무 쉽다는 문제점 발생\n",
    "# 원인 분석\n",
    "# 원인: train, valid, test 를 이루고 있는 AI-Generated Text가 모두 GPT-4o-mini 모델로 구성됨.\n",
    "# 즉, GPT-4o-mini 모델로 만들어진 AI-Generated Text로 학습을 했으니 그 패턴을 파악하게 돼서 GPT-4-mini 모델로 만들어진 Test dataset이 난이도가 쉬워서 정확하게 분류가 가능하게 된 것\n",
    "# 해결 방안: train & valid data와 test data의 distribution을 다르게 하기 위해서, test dataset은 GPT-4o-mini Model뿐만 아니라 최대한 다양한 모델을 이용해서 구축하게 되면 Custom dataset의 난이도가 더 향상될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset_v2: Human Text 4500개, AI-Text: GPT-4o-mini Text 4500개 총 9000개\n",
    "# valid dataset_v2: Human Text 450개, AI-Text: GPT-4o-mini Text 450개 총 900개\n",
    "\n",
    "# test dataset_v2: Human Text 450개, \n",
    "# AI-Text:\n",
    "# 1.'gpt-4o' 50개\n",
    "# 2.'meta-llama/Llama-3.2-8B-Instruct' 50개\n",
    "# 3.'Qwen/Qwen2.5-7B-Instruct' 50개\n",
    "# 4.'Qwen/Qwen2.5-14B-Instruct' 50개\n",
    "# 5.'Qwen/Qwen2.5-1.5B-Instruct' 50개\n",
    "# 6.'Qwen/Qwen2.5-0.5B-Instruct' 50개\n",
    "# 7.'gpt-3.5-turbo' 50개 \n",
    "# 8.'o1-mini' 50개 \n",
    "# 9.'gpt-4o-mini' 50개 \n",
    "# 총 900개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import AutoProcessor, BitsAndBytesConfig, pipeline, AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config & Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 1\n",
    "    \n",
    "    MODEL_1 = \"gpt-4o\" \n",
    "    MODEL_2 = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "    MODEL_3 = 'Qwen/Qwen2.5-7B-Instruct'\n",
    "    MODEL_4 = 'Qwen/Qwen2.5-14B-Instruct'\n",
    "    MODEL_5 = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
    "    MODEL_6 = 'Qwen/Qwen2.5-0.5B-Instruct'\n",
    "    MODEL_7 = 'gpt-3.5-turbo' \n",
    "    MODEL_8 = 'o1-mini' \n",
    "    MODEL_9 = 'gpt-4o-mini' \n",
    "    \n",
    "    # api key가 담긴 yaml파일 (해당 yaml 파일은 .gitignore에 반드시 추가해야 함!!!)\n",
    "    API_CONFIG_PATH = './config.yaml'\n",
    "    \n",
    "    # 1_dataset_preprocess.ipynb의 결과로 나온 전처리된 Human Dataset 경로\n",
    "    DF_HUMAN_TEST_PATH = './df_human_test.csv'\n",
    "    \n",
    "    # AI-Generated Text까지 포함된 csv파일의 output 경로\n",
    "    DF_HUMAN_AI_TEST_PATH_1 = './df_human_ai_test_1_gpt-4o.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_2 = './df_human_ai_test_2_Llama-3_1-8B-Instruct.csv' \n",
    "    DF_HUMAN_AI_TEST_PATH_3 = './df_human_ai_test_3_Qwen2_5-7B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_4 = './df_human_ai_test_4_Qwen2_5-14B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_5 = './df_human_ai_test_5_Qwen2_5-1_5B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_6 = './df_human_ai_test_6_Qwen2_5-0_5B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_7 = './df_human_ai_test_7_gpt-3_5_turbo.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_8 = './df_human_ai_test_8_o1-mini.csv' \n",
    "    DF_HUMAN_AI_TEST_PATH_9 = './df_human_ai_test_9_gpt-4o-mini.csv'\n",
    "    \n",
    "    # Final Dataset output 경로 (Human Text, AI Text, Label 존재)\n",
    "    DF_FINAL_TEST_PATH = './df_final_test_v2.csv'\n",
    "    \n",
    "    # CACHE_DIR = '/data/ksh1234/ksh1234/huggingface_cache' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT TEST DATASET INTO 50 * 9\n",
    "test_dataset = pd.read_csv(CFG.DF_HUMAN_TEST_PATH)\n",
    "split_datasets = []\n",
    "chunk_size = 50\n",
    "\n",
    "for i in range(0, len(test_dataset), chunk_size):\n",
    "    split_datasets.append(test_dataset.iloc[i:i + chunk_size])\n",
    "\n",
    "test_dataset_1 = split_datasets[0]\n",
    "test_dataset_2 = split_datasets[1]\n",
    "test_dataset_3 = split_datasets[2]\n",
    "test_dataset_4 = split_datasets[3]\n",
    "test_dataset_5 = split_datasets[4]\n",
    "test_dataset_6 = split_datasets[5]\n",
    "test_dataset_7 = split_datasets[6]\n",
    "test_dataset_8 = split_datasets[7]\n",
    "test_dataset_9 = split_datasets[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: Qwen/Qwen2.5-14B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595b5651dfbe45f48303f5878909b116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3138/641297606.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_dataset_4['AI_Generated_Text'] = \"\"\n",
      "/tmp/ipykernel_3138/641297606.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_dataset_4['Model'] = \"\"\n",
      "\n",
      "00%|██████████| 50/50 [28:33<00:00, 34.27s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_name = CFG.MODEL_4\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    # load_in_4bit=True,  \n",
    "    device_map=\"auto\",  \n",
    "    quantization_config=bnb_config,\n",
    "\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "test_dataset_4['AI_Generated_Text'] = \"\"\n",
    "test_dataset_4['Model'] = \"\"\n",
    "\n",
    "for idx, row in tqdm(test_dataset_4.iterrows(), total=len(test_dataset_4)):\n",
    "    input_text = row['essay_prompt']\n",
    "    student_grade = row['student_grade']\n",
    "    school, grade = student_grade.split('_')\n",
    "    if school == '중등':\n",
    "        school = school[0]  # 중등인 경우 '중'만 가져옴\n",
    "    \n",
    "    # 학교 수준에 따라 다르게 설정하는 시스템 프롬프트\n",
    "    grade_system_prompt = f\"대한민국의 {school}학교 {grade} 학생 수준으로 답하시오. 마크다운 용법을 사용하지 말고 학생이 글을 쓰듯이 답하시오.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": grade_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": input_text},\n",
    "    ]\n",
    "\n",
    "    # 메시지를 토큰화 및 모델 입력 생성\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=1024\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    llm_output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    test_dataset_4.at[idx, 'AI_Generated_Text'] = llm_output\n",
    "    test_dataset_4.at[idx, 'Model'] = model_name\n",
    "\n",
    "test_dataset_4.to_csv(CFG.DF_HUMAN_AI_TEST_PATH_4, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150    반려동물을 키우는 것은 쉽지 않은 일입니다. 반려동물을 키우면서 금전적인 문제나 시...\n",
       "151    반려동물을 키우는 것은 쉽지 않은 일입니다. 그래서 반려동물을 키우기 전에 잘 알아...\n",
       "152    반려동물을 키우는 것은 정말 재미있지만, 그 책임감은 무겁습니다. 반려동물이 버려지...\n",
       "153    반려동물을 키우는 것은 책임감이 있어야 하는 중요한 일이라고 생각해요. 반려동물을 ...\n",
       "154    반려동물을 키우는 것은 정말 재미있고 즐거운 일이지만, 그 책임감도 무시할 수 없습...\n",
       "155    반려동물을 키우는 것은 책임감이 있어야 하는 일이에요. 반려동물을 유기하는 건 잘못...\n",
       "156    반려동물을 키우는 것은 정말 재미있고 즐거운 일이지만, 그 책임감을 잘 생각해야 한...\n",
       "157    반려동물을 키우는 것은 정말 재미있고 사랑스러운 일입니다. 하지만 반려동물을 키울 ...\n",
       "158    반려동물을 키우는 것은 쉽지 않은 일입니다. 그래서 반려동물을 키우기 전에 미리 준...\n",
       "159    반려동물을 키우는 것은 정말 재미있고 즐거운 일이지만, 그 반려동물을 책임지는 것도...\n",
       "160    반려동물을 키우는 것은 책임감이 필요하다고 생각해요. 반려동물을 그냥 귀엽다고 데려...\n",
       "161    반려동물을 키우는 것은 참 좋은 일이지만, 그 책임감이 중요하다는 것을 잊으면 안 ...\n",
       "162    반려동물을 키우는 것은 참 좋은 일이지만, 그 반려동물을 책임지는 것이 중요하다고 ...\n",
       "163    반려동물을 키우는 것은 참 좋은 일이지만, 그 책임감도 무시할 수 없습니다. 반려동...\n",
       "164    반려동물을 키우는 것은 정말 재미있지만 책임감이 있어야 한다고 생각해요. 반려동물을...\n",
       "165    반려동물을 키우는 것은 쉽지 않은 일입니다. 그래서 반려동물을 키우는 사람들에게 책...\n",
       "166    반려동물을 키우는 것은 아주 재미있지만 책임감이 필요하다는 것을 알아야 합니다. 반...\n",
       "167    반려동물을 키우는 것은 정말 재미있고 즐거운 일이지만, 그 책임감도 무시할 수 없습...\n",
       "168    반려동물을 키우는 것은 참 좋은 일이지만, 그 책임감도 중요하다고 생각해요. 반려동...\n",
       "169    반려동물을 키우는 것은 쉽지 않은 일이란 걸 알아요. 그저 귀엽다고 해서 반려동물을...\n",
       "170    반려동물을 키우는 것은 책임감이 필요한 일이라고 생각해요. 반려동물은 그냥 재미있어...\n",
       "171    반려동물을 키우는 것은 아주 즐거운 일입니다. 하지만 반려동물을 잃어버리거나 버리는...\n",
       "172    반려동물을 키우는 것은 쉽지 않은 일입니다. 그래서 반려동물을 유기하는 일이 발생하...\n",
       "173    반려동물을 키우는 것은 정말 좋은 일이지만, 그 책임감도 중요하다고 생각해요. 반려...\n",
       "174    반려동물을 키우는 것은 정말 재미있고 즐거운 일이지만, 그 반려동물을 책임지는 것은...\n",
       "175    반려동물을 키우는 것은 정말 재미있지만, 그 책임감도 무시할 수 없습니다. 반려동물...\n",
       "176    반려동물을 키우는 것은 아주 좋은 일입니다. 반려동물들은 우리에게 많은 사랑과 행복...\n",
       "177    반려동물을 키우는 것은 정말 재미있고 즐거운 일이지만, 그 반려동물을 책임지는 것도...\n",
       "178    반려동물을 키우는 것은 아주 좋은 일이지만, 그 책임감을 무시하면 안되요. 반려동물...\n",
       "179    반려동물을 키우는 것은 정말 재미있고 사랑스러운 일이지만, 그 책임감을 무시해서는 ...\n",
       "180    저는 소설 중에서도 판타지 장르를 좋아합니다. 판타지 장르는 현실 세계에서는 있을 ...\n",
       "181    저는 실제로 친구와 장난을 주고 받다 보니 친구가 불쾌해하는 상황을 겪은 적이 있습...\n",
       "182    제가 좋아하는 장르는 '액션' 장르입니다. 액션 장르는 긴장감 넘치는 전개와 역동적...\n",
       "183    제가 경험했던 무시와 배려 부족으로 인한 결과를 말씀드리면, 초등학교 때의 일입니다...\n",
       "184    저는 액션 영화와 소설을 좋아하는데, 그 중에서도 특히 '론inho'라는 이름의 작...\n",
       "185    제가 경험했던 무시나 배려하지 않은 사례를 말씀드리면, 작년 겨울에 학교에서 친구들...\n",
       "186    내년에 사회인으로 첫발을 내딛게 되는 상황을 생각하면 뭔가 새로운 목표가 생기네요....\n",
       "187    저는 액션 영화를 좋아합니다. 그 중에서도 '매트릭스'라는 영화를 가장 재미있게 봤...\n",
       "188    저는 아직 대학 진학 후 어떤 전공을 선택해야 할지 확실하게 결정하지 못했습니다. ...\n",
       "189    저는 내년에 대학에 진학해서 컴퓨터공학과 전공을 하고 싶어요. 이 계기는 중학교 때...\n",
       "190    저는 소설을 좋아하는데, 그 중에서도 판타지 장르가 가장 좋습니다. 판타지는 현실에...\n",
       "191    제가 경험했던 이런 상황은 초등학교 시절에 있었어요. 그때는 아직 고등학생이 아니었...\n",
       "192    제가 좋아하는 장르는 '액션' 장르입니다. 그 중에서도 특히 범죄 추적이나 스파이 ...\n",
       "193    저는 아직 대학 진학 후 어떤 전공을 선택할지, 그 후에는 어떤 직업을 가지게 될지...\n",
       "194    제가 좋아하는 장르는 액션 영화와 모험 소설입니다. 이 두 장르는 항상 긴장감 넘치...\n",
       "195    저는 액션 장르를 좋아하는데, 그 중에서도 '매트릭스'라는 영화를 가장 재미있게 봤...\n",
       "196    저는 액션 영화와 소설을 좋아하는데, 그 중에서도 특히 스파이물이 제일 재미있다고 ...\n",
       "197    제가 경험한 무시당한 상황이 하나 있어요. 작년 겨울, 친구들과 함께 등산을 가려고...\n",
       "198    제가 좋아하는 장르는 '액션' 장르입니다. 그 중에서도 액션이 넘치는 영화를 보면 ...\n",
       "199    저는 제가 친구와 함께 있었을 때, 친구가 좋아하는 주제에 대해 이야기하고 있는데 ...\n",
       "Name: AI_Generated_Text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_4['AI_Generated_Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
