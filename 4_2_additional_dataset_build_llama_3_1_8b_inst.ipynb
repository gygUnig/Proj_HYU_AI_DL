{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Seunghee Kim\n",
    "- Created on: 2024-12-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Explain\n",
    "# 기존에 train / valid / test 데이터셋을 구축해서 deberta-v3-xsmall 모델로 train data 학습 후 test dataset에 대해 예측했는데, 정확도 0.99가 나오게 됨.\n",
    "# 데이터셋의 난이도가 너무 쉽다는 문제점 발생\n",
    "# 원인 분석\n",
    "# 원인: train, valid, test 를 이루고 있는 AI-Generated Text가 모두 GPT-4o-mini 모델로 구성됨.\n",
    "# 즉, GPT-4o-mini 모델로 만들어진 AI-Generated Text로 학습을 했으니 그 패턴을 파악하게 돼서 GPT-4-mini 모델로 만들어진 Test dataset이 난이도가 쉬워서 정확하게 분류가 가능하게 된 것\n",
    "# 해결 방안: train & valid data와 test data의 distribution을 다르게 하기 위해서, test dataset은 GPT-4o-mini Model뿐만 아니라 최대한 다양한 모델을 이용해서 구축하게 되면 Custom dataset의 난이도가 더 향상될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset_v2: Human Text 4500개, AI-Text: GPT-4o-mini Text 4500개 총 9000개\n",
    "# valid dataset_v2: Human Text 450개, AI-Text: GPT-4o-mini Text 450개 총 900개\n",
    "\n",
    "# test dataset_v2: Human Text 450개, \n",
    "# AI-Text:\n",
    "# 1.'gpt-4o' 50개\n",
    "# 2.'meta-llama/Llama-3.2-8B-Instruct' 50개\n",
    "# 3.'Qwen/Qwen2.5-7B-Instruct' 50개\n",
    "# 4.'Qwen/Qwen2.5-14B-Instruct' 50개\n",
    "# 5.'Qwen/Qwen2.5-1.5B-Instruct' 50개\n",
    "# 6.'Qwen/Qwen2.5-0.5B-Instruct' 50개\n",
    "# 7.'gpt-3.5-turbo' 50개 \n",
    "# 8.'o1-mini' 50개 \n",
    "# 9.'gpt-4o-mini' 50개 \n",
    "# 총 900개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import torch\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config & Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 1\n",
    "    \n",
    "    MODEL_1 = \"gpt-4o\" \n",
    "    MODEL_2 = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "    MODEL_3 = 'Qwen/Qwen2.5-7B-Instruct'\n",
    "    MODEL_4 = 'Qwen/Qwen2.5-14B-Instruct'\n",
    "    MODEL_5 = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
    "    MODEL_6 = 'Qwen/Qwen2.5-0.5B-Instruct'\n",
    "    MODEL_7 = 'gpt-3.5-turbo' \n",
    "    MODEL_8 = 'o1-mini' \n",
    "    MODEL_9 = 'gpt-4o-mini' \n",
    "    \n",
    "    # api key가 담긴 yaml파일 (해당 yaml 파일은 .gitignore에 반드시 추가해야 함!!!)\n",
    "    API_CONFIG_PATH = './config.yaml'\n",
    "    \n",
    "    # 1_dataset_preprocess.ipynb의 결과로 나온 전처리된 Human Dataset 경로\n",
    "    DF_HUMAN_TEST_PATH = './df_human_test.csv'\n",
    "    \n",
    "    # AI-Generated Text까지 포함된 csv파일의 output 경로\n",
    "    DF_HUMAN_AI_TEST_PATH_1 = './df_human_ai_test_1_gpt-4o.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_2 = './df_human_ai_test_2_Llama-3_1-8B-Instruct.csv' \n",
    "    DF_HUMAN_AI_TEST_PATH_3 = './df_human_ai_test_3_Qwen2_5-7B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_4 = './df_human_ai_test_4_Qwen2_5-14B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_5 = './df_human_ai_test_5_Qwen2_5-1_5B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_6 = './df_human_ai_test_6_Qwen2_5-0_5B-Instruct.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_7 = './df_human_ai_test_7_gpt-3_5_turbo.csv'\n",
    "    DF_HUMAN_AI_TEST_PATH_8 = './df_human_ai_test_8_o1-mini.csv' \n",
    "    DF_HUMAN_AI_TEST_PATH_9 = './df_human_ai_test_9_gpt-4o-mini.csv'\n",
    "    \n",
    "    # Final Dataset output 경로 (Human Text, AI Text, Label 존재)\n",
    "    DF_FINAL_TEST_PATH = './df_final_test_v2.csv'\n",
    "    \n",
    "    # CACHE_DIR = '/data/ksh1234/ksh1234/huggingface_cache' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT TEST DATASET INTO 50 * 9\n",
    "test_dataset = pd.read_csv(CFG.DF_HUMAN_TEST_PATH)\n",
    "split_datasets = []\n",
    "chunk_size = 50\n",
    "\n",
    "for i in range(0, len(test_dataset), chunk_size):\n",
    "    split_datasets.append(test_dataset.iloc[i:i + chunk_size])\n",
    "\n",
    "test_dataset_1 = split_datasets[0]\n",
    "test_dataset_2 = split_datasets[1]\n",
    "test_dataset_3 = split_datasets[2]\n",
    "test_dataset_4 = split_datasets[3]\n",
    "test_dataset_5 = split_datasets[4]\n",
    "test_dataset_6 = split_datasets[5]\n",
    "test_dataset_7 = split_datasets[6]\n",
    "test_dataset_8 = split_datasets[7]\n",
    "test_dataset_9 = split_datasets[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: meta-llama/Llama-3.1-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = CFG.MODEL_2\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "test_dataset_2['AI_Generated_Text'] = \"\"\n",
    "test_dataset_2['Model'] = \"\"\n",
    "\n",
    "for idx, row in tqdm(test_dataset_2.iterrows(), total=len(test_dataset_2)):\n",
    "    input_text = row['essay_prompt']\n",
    "    student_grade = row['student_grade']\n",
    "    school, grade = student_grade.split('_')\n",
    "    if school == '중등':\n",
    "        school = school[0]  # 중등인 경우 '중'만 가져옴\n",
    "    \n",
    "    # 학교 수준에 따라 다르게 설정하는 시스템 프롬프트\n",
    "    grade_system_prompt = f\"대한민국의 {school}학교 {grade} 학생 수준으로 답하시오. 마크다운 용법을 사용하지 말고 학생이 글을 쓰듯이 답하시오.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": grade_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": input_text},\n",
    "    ]\n",
    "    \n",
    "    outputs = pipe(\n",
    "        messages,\n",
    "        max_new_tokens=1024,\n",
    "    )\n",
    "    \n",
    "    llm_output = outputs[0][\"generated_text\"]  \n",
    "    \n",
    "    test_dataset_2.at[idx, 'AI_Generated_Text'] = llm_output\n",
    "    test_dataset_2.at[idx, 'Model'] = model_id\n",
    "\n",
    "test_dataset_2.to_csv(CFG.DF_HUMAN_AI_TEST_PATH_2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미래의 도시는 어떤 모습일까요? 기술의 발전으로 인해 자동차가 하늘을 날아다니고 사람들은 로봇과 자연스럽게 대화하며 지낼까요? 아니면 더 이상의 환경 파괴를 하지 말자고 결정되어 기계를 줄이고 숲과 동물들과 함께 어울려 살아가게 될까요? 외계인과 소통하는 세계가 되어있을 수도 있겠네요! 자신이 생각하는 미래 도시의 이름을 지어주세요. 그리고 미래 도시의 모습을 상상하여 자유롭게 작성해주세요. 그렇게 생각한 이유를 작성해주면 더욱더 좋을 것 같아요.\\'}, {\\'role\\': \\'assistant\\', \\'content\\': \\'미래의 도시가 어떤 모습일까요? 저는 \"에코시티\" 라는 이름의 도시를 상상해보고 싶습니다.\\\\n\\\\n에코시티는 기존의 도시가 환경을 파괴하는 것과는 반대인 도시입니다. 에코시티는 지구를 보호하고 자연과 함께 살아가는 도시입니다. 에코시티는 기계를 줄이고 자연을 존중하는 도시입니다.\\\\n\\\\n에코시티의 주민들은 환경을 보호하는 데에 관심이 많습니다. 도시의 건축물은 자연과 조화를 이룹니다. 건물은 높고 얕은 형태로-designed 되어서 자연의 경관을 훼손하지 않습니다. 도시의 거리에는 많은 숲이 있고, 동물들이 자유롭게 살 수 있는 공간이 많습니다.\\\\n\\\\n에코시티의 주민들은 로봇과 자연스럽게 대화할 수 있습니다. 로봇들은 도시의 관리와 유지보수를 도와주고, 주민들의 삶을 편리하게 만듭니다. 하지만 로봇들은 주민들의 삶을 방해하지 않습니다. 주민들은 로봇과 자연스럽게 대화할 수 있게되어, 로봇이 주민들의 삶을 편리하게 만드는 것을 보면서, 로봇과 자연스럽게 대화하는 것이 자연스러워진다는 것을 알 수 있습니다.\\\\n\\\\n에코시티의 주민들은 외계인과 소통할 수 있습니다. 에코시티는 외계인과 소통할 수 있는 도시로, 외계인과 교류하는 것이 가능합니다. 에코시티는 세계의 평화를 유지하는 데에 기여할 수 있습니다.\\\\n\\\\n에코시티는 기계를 줄이고 자연을 존중하는 도시입니다. 에코시티는 지구를 보호하고 자연과 함께 살아가는 도시입니다. 에코시티는 미래의 도시로, 자연과 함께 살아가는 도시입니다.\\\\n\\\\n에코시티의 이름을 지은 이유는 에코를 뜻하는 \"에코\"와 도시를 뜻하는 \"시티\"를 합친 것입니다. 에코는 지구를 보호하고 자연을 존중하는 것을 뜻합니다. 에코시티는 지구를 보호하고 자연을 존중하는 도시입니다.\\\\n\\\\n에코시티의 도시를 상상한 이유는, 환경 파괴를 줄이고 자연과 함께 살아가는 것이 중요하다는 것을 알기 때문입니다. 에코시티는 지구를 보호하고 자연과 함께 살아가는 도시입니다. 에코시티는 미래의 도시로, 자연과 함께 살아가는 도시입니다.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(CFG.DF_HUMAN_AI_TEST_PATH_2)\n",
    "\n",
    "def clean_ai_generated_text(text):\n",
    "    text = text.replace(\"[{'role': 'system', 'content': '대한민국의 중학교 1학년 학생 수준으로 답하시오. 마크다운 용법을 사용하지 말고 학생이 글을 쓰듯이 답하시오.'}, {'role': 'user', 'content': '\", '')\n",
    "    text = text.rstrip(\"'}]\")\n",
    "    return text\n",
    "\n",
    "df['AI_Generated_Text'] = df['AI_Generated_Text'].apply(clean_ai_generated_text)\n",
    "\n",
    "# 결과 확인\n",
    "df.to_csv(CFG.DF_HUMAN_AI_TEST_PATH_2, index=False)\n",
    "df['AI_Generated_Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
